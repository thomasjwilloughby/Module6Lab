---
title: "Multiple linear regression"
author: "Thomas Willoughby"
date: "`r Sys.Date()`"
output: openintro::lab_report
---

```{r load-packages, message=FALSE}
library(tidyverse)
library(openintro)
library(GGally)
library(broom)
```

### Exercise 1

This is an observation study. Given the study design we cannot answer the question posed, as in an observational study one cannot determine causation only correlation.

### Exercise 2

The distribution is left skewed. This indicates that there are few students giving the professors low rating. This is roughly what I would expect to see as there will always be some ratting at the lower end.

```{r}
ggplot(data = evals, aes(x = score)) +
  geom_histogram()
```

### Exercise 3

The maximum beauty average seems to decrease as age increases.

```{r}
ggplot(data = evals, aes(x = age, y = bty_avg)) +
  geom_point()
```

### Exercise 4

```{r}
ggplot(data = evals, aes(x = bty_avg, y = score)) +
  geom_jitter()

ggplot(data = evals, aes(x = bty_avg, y = score)) +
  geom_jitter()
```

### Exercise 5

```{r}
# TODO: ^DO THIS^
m_bty <- lm(score ~ bty_avg, data = evals)
summary(m_bty)
```

$$
\hat{score} = 0.06664\cdot \text{bty_avg} +3.88034
$$

The slope of 0.06664 indicates that for every increase of one in beauty average score goes up by 0.06664. Yes, the average beauty score is statisticaly significant predictor for score. However It is not a practicaly significant predictor.

### Exercise 6

```{r}
evals_aug1 <- augment(m_bty)

evals_aug1 %>% ggplot(aes(x = .resid)) +
  geom_histogram()
```

The distribution of residuals does not approximately normal.

```{r}
evals_aug1 %>% ggplot(aes(x = .fitted, y = .resid)) +
  geom_point()
```

The scatterplot does not show any patterns.

### Exercise 7

```{r}
m_bty_gen <- lm(score ~ bty_avg + gender, data = evals)
tidy(m_bty_gen)


evals_aug2 <- augment(m_bty_gen)

evals_aug2 %>% ggplot(aes(x = .resid)) +
  geom_histogram()

evals_aug2 %>% ggplot(aes(x = .fitted, y = .resid)) +
  geom_point()

# TODO: compltete exercies 8,9,10
```
### Exercise 11

I would expect the variable with the highest p-value to be $\texttt{cls_perc_eval}$ as i would not expect the percentage of students that completed the evaluation would have a affect on the score of a professor.

### Exercise 12

In this full model, $\texttt{cls_profs}$ (Number of professors teaching sections in course in sample: single, multiple.) has the highest p-value of 

```{r}
m_full <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
tidy(m_full)
```

### Exercise 13

The coefficient of the ethnicity variable 0.1869649363	represents and increase of 0.1869649363 on average when the variable is "not minority" relative to the equivalent with ethnicity as "minority".

### Exercise 14

Removing $\texttt{cls_profs}$ increase the adjusted $R^2$ value the most.

```{r}
m_rank <- lm(score ~ gender + ethnicity + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
m_gender <- lm(score ~ rank + ethnicity + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
m_ethnicity <- lm(score ~ rank + gender  + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
m_language <- lm(score ~ rank + gender + ethnicity + age + cls_perc_eval 
             + cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
m_age <- lm(score ~ rank + gender + ethnicity + language + cls_perc_eval 
             + cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
m_clsperceval <- lm(score ~ rank + gender + ethnicity + language + age +  
            cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)
m_students <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval 
             + cls_level + cls_profs + cls_credits + bty_avg, data = evals)

m_level <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval 
             + cls_students +  cls_profs + cls_credits + bty_avg, data = evals)

m_profs <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_credits + bty_avg, data = evals)

m_credits <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_profs + bty_avg, data = evals)

m_btyavg <- lm(score ~ rank + gender + ethnicity + language + age + cls_perc_eval 
             + cls_students + cls_level + cls_profs + cls_credits , data = evals)

get_adj_r2 <- function(m_var) {
  summary(m_var)$adj.r.squared
}

r2_rank <- get_adj_r2(m_rank)
r2_gender <- get_adj_r2(m_gender)
r2_ethnicity <- get_adj_r2(m_ethnicity)
r2_language <- get_adj_r2(m_language)
r2_age <- get_adj_r2(m_age)
r2_clsperceval <- get_adj_r2(m_clsperceval)
r2_students <- get_adj_r2(m_students)
r2_level <- get_adj_r2(m_level)
r2_profs <- get_adj_r2(m_profs)
r2_btyavg <- get_adj_r2(m_btyavg)

```

```{r}
r2_rank
```

```{r}
r2_gender
```

```{r}
r2_ethnicity
```

```{r}
r2_language
```

```{r}
r2_age
```

```{r}
r2_clsperceval
```

```{r}
r2_students
```

```{r}
r2_level
```

```{r}
r2_profs
```

```{r}
r2_btyavg
```
The variable with the highest p-value is $\texttt{cls_profs}$

```{r}
tidy(m_profs)
```

The coefficients of the other explanatory variables didn't change significantly with the removal of $\texttt{cls_profs}$. What this indicates about of the co-linearity of the variables is that there was at least one co-linear variable.

### Exerise 15

```{r}
# TODO: Finish
```

$$
\hat{score} = 
$$